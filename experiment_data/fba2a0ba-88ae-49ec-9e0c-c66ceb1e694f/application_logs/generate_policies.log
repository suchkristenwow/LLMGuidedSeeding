initting the Policy Generator with these arguments: 
Namespace(config_path='/home/miles/projects/LLMGuidedSeeding/configs/example_config.toml', logging_dir='/home/miles/projects/LLMGuidedSeeding/experiment_data/fba2a0ba-88ae-49ec-9e0c-c66ceb1e694f/policy_generation_logs', plot_bounds_path='/home/miles/projects/LLMGuidedSeeding/random_path.csv', prompt_path='/home/miles/projects/LLMGuidedSeeding/prompts/ex_query.txt')

parsing prompt to get constraints ...
Enhanced Query: You are guiding an autonomous robotic agent to execute the prompt given below. The robot is supposed to help ecologists with tasks related to revegetation of degraded 
rangelands.

The robot is able to observe landmarks via RGB cameras and it is able to plant seeds. 

Given the following prompt, identify any relevant constraints or goal landmarks in the form of a dictionary so that I can write a policy to execute the desired task. 

The keys to this dictionary should be the strings "avoid","goal_lms","pattern","landmark_offset","search", "seed", and "pattern_offset". Here, seed is a string of a boolean variable 
which is true if the robot should plant in the specified pattern. 

For example, if the prompt was: "Plant 10 cm away from any shrubs in the plot", return {"goal_lms":"shrub","landmark_offset":0.1,"seed":"True"}. Or, if the prompt was 
"Seed along the fenceline in a straight row, 15 cm apart", return {"goal_lms":"fence","pattern_offset":0.15,"pattern":"line","seed":"True"}. 
Finally, the prompt: "Count how many shrubs are in the plot." would return {"search":"shrubs","seed":"False"}.

If you're not sure how to format the constraints into this dictionary format, return a question in the form of a string that would help allow you to parse the prompt 
into the dictionary format. An example of a follow-up question could be "I'm sorry, I'm not sure how to parse your prompt. Currently, I want to format the constraints of 
your prompt into a dictionary with the keys: "avoid","goal_lms","pattern","landmark_offset","search", and "pattern_offset". Do you think your prompt constraints can be categorized 
like this or should I edit my constraint dictionary format?"

Prompt: Plant in 1mx1m grid in the bounded area. Avoid driving over wherever youâ€™ve planted or any conmods.


llm_result: {"avoid":"planted area, conmods","pattern":"grid","pattern_offset":1,"seed":"True"}

results_str:  {"avoid":"planted area, conmods","pattern":"grid","pattern_offset":1,"seed":"True"}
constraints:  {'avoid': 'planted area, conmods', 'pattern': 'grid', 'pattern_offset': 1, 'seed': True}
building policy...
feedback is none!
Policy:  1. Start by checking if the robot is inside the plot bounds using the lidar-inertial odometry and GPS for localization. If the robot is outside the plot bounds, navigate to the nearest point within the bounds using the shortest possible route.

2. Use the RGB cameras to create an initial map of the plot, identifying any existing planted areas and conmods to be avoided.

3. Begin at one corner of the plot, selecting it as the starting point for the grid pattern.

4. From this starting point, calculate the grid positions where seeds need to be planted based on the 1mx1m pattern offset given in the constraints. Ensure that these positions are within the plot bounds.

5. For each calculated grid position:
   - Check the path to this position, ensuring it avoids all areas listed under the 'avoid' key in the constraint dictionary. If a path cannot be found, notify the user and ask for instructions.
   - Once at the position, plant a seed. Add this location to the system's memory list of planted locations.
   - Use the RGB cameras to observe the immediate environment for any new obstacles, updating the map as needed.

6. Continue this process until all grid positions within the plot bounds have been planted.

7. Once all seeds have been planted, notify the user of completion. Provide the user with the list of all planted locations for their records. 

8. Standby for any further instructions from the user.
Feedback: enhanced verification response:  The following paragraph is feedback from the user on a policy. Based on the following response, does the user approve of this policy? Return "True" if so, and "False" otherwise.
If the user suggests any changes, return False. 
Looks good!
verifying the policy; this is the llm result: True
Found a valid policy approved by the human!
