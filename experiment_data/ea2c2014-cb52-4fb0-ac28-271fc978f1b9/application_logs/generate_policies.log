initting the Policy Generator with these arguments: 
Namespace(config_path='/home/miles/projects/LLMGuidedSeeding/configs/example_config.toml', logging_dir='/home/miles/projects/LLMGuidedSeeding/experiment_data/ea2c2014-cb52-4fb0-ac28-271fc978f1b9/policy_generation_logs', plot_bounds_path='/home/miles/projects/LLMGuidedSeeding/random_path.csv', prompt_path='/home/miles/projects/LLMGuidedSeeding/prompts/ex_query.txt')

parsing prompt to get constraints ...
Enhanced Query: You are guiding an autonomous robotic agent to execute the prompt given below. The robot is supposed to help ecologists with tasks related to revegetation of degraded 
rangelands.

The robot is able to observe landmarks via RGB cameras and it is able to plant seeds. 

Given the following prompt, identify any relevant constraints or goal landmarks in the form of a dictionary so that I can write a policy to execute the desired task. 

The keys to this dictionary should be the strings "avoid","goal_lms","pattern","landmark_offset","search", "seed", and "pattern_offset". Here, seed is a string of a boolean variable 
which is true if the robot should plant in the specified pattern. 

For example, if the prompt was: "Plant 10 cm away from any shrubs in the plot", return {"goal_lms":"shrub","landmark_offset":0.1,"seed":"True"}. Or, if the prompt was 
"Seed along the fenceline in a straight row, 15 cm apart", return {"goal_lms":"fence","pattern_offset":0.15,"pattern":"line","seed":"True"}. 
Finally, the prompt: "Count how many shrubs are in the plot." would return {"search":"shrubs","seed":"False"}.

If you're not sure how to format the constraints into this dictionary format, return a question in the form of a string that would help allow you to parse the prompt 
into the dictionary format. An example of a follow-up question could be "I'm sorry, I'm not sure how to parse your prompt. Currently, I want to format the constraints of 
your prompt into a dictionary with the keys: "avoid","goal_lms","pattern","landmark_offset","search", and "pattern_offset". Do you think your prompt constraints can be categorized 
like this or should I edit my constraint dictionary format?"

Prompt: Plant in 1mx1m grid in the bounded area. Avoid driving over wherever youâ€™ve planted or any conmods.


llm_result: {"avoid":"planted areas, conmods","pattern":"grid","pattern_offset":1,"seed":"True"}

results_str:  {"avoid":"planted areas, conmods","pattern":"grid","pattern_offset":1,"seed":"True"}
constraints:  {'avoid': 'planted areas, conmods', 'pattern': 'grid', 'pattern_offset': 1, 'seed': True}
building policy...
feedback is none!
Policy:  1. Check the initial location of the robot. If it is outside the plot bounds, plan and execute the shortest route possible to the first grid coordinate inside the bounds.

2. Once inside the plot bounds, begin with the first grid coordinate (considering pattern offset of 1m). Check for any objects in the 'avoid' list in this area.

3. If any objects from the 'avoid' list (in this case, 'planted areas, conmods') are detected within the 1m vicinity of the grid point, move to the next grid coordinate and repeat step 2.

4. If no objects from the 'avoid' list are detected in the 1m vicinity of the grid point, proceed with planting a seed at the grid coordinate. 

5. Add the current location to the system memory under 'planted locations'.

6. Move to the next grid point, considering the 1m x 1m pattern offset and repeat steps 2 through 5. 

7. Continue this process until all grid points within the plot bounds have been covered.

8. If the robot encounters a landmark or object it cannot identify, pause the task and notify the user saying, "I can't find {landmark}, where should I look?"

9. Based on user feedback, identify the unknown landmark or object and update the 'avoid' list, if necessary. Then, resume the task from where it was paused.

10. After all grid points within the plot bounds have been covered and seeded (where possible), conclude the task and report back to the user.
Feedback: Received message from backend: whoooooooooo hoooooo that worked and thank you so much
enhanced verification response:  The following paragraph is feedback from the user on a policy. Based on the following response, does the user approve of this policy? Return "True" if so, and "False" otherwise.
If the user suggests any changes, return False. 
looks good
verifying the policy; this is the llm result: True
Found a valid policy approved by the human!
Human response: whoooooooooo hoooooo that worked and thank you so much
