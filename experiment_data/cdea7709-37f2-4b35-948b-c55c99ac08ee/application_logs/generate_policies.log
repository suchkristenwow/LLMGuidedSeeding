initting the Policy Generator with these arguments: 
Namespace(config_path='/home/miles/projects/LLMGuidedSeeding/configs/example_config.toml', logging_dir='/home/miles/projects/LLMGuidedSeeding/experiment_data/cdea7709-37f2-4b35-948b-c55c99ac08ee/policy_generation_logs', plot_bounds_path='/home/miles/projects/LLMGuidedSeeding/random_path.csv', prompt_path='/home/miles/projects/LLMGuidedSeeding/prompts/ex_query.txt')

parsing prompt to get constraints ...
Enhanced Query: You are guiding an autonomous robotic agent to execute the prompt given below. The robot is supposed to help ecologists with tasks related to revegetation of degraded 
rangelands.

The robot is able to observe landmarks via RGB cameras and it is able to plant seeds. 

Given the following prompt, identify any relevant constraints or goal landmarks in the form of a dictionary so that I can write a policy to execute the desired task. 

The keys to this dictionary should be the strings "avoid","goal_lms","pattern","landmark_offset","search", "seed", and "pattern_offset". Here, seed is a string of a boolean variable 
which is true if the robot should plant in the specified pattern. 

For example, if the prompt was: "Plant 10 cm away from any shrubs in the plot", return {"goal_lms":"shrub","landmark_offset":0.1,"seed":"True"}. Or, if the prompt was 
"Seed along the fenceline in a straight row, 15 cm apart", return {"goal_lms":"fence","pattern_offset":0.15,"pattern":"line","seed":"True"}. 
Finally, the prompt: "Count how many shrubs are in the plot." would return {"search":"shrubs","seed":"False"}.

If you're not sure how to format the constraints into this dictionary format, return a question in the form of a string that would help allow you to parse the prompt 
into the dictionary format. An example of a follow-up question could be "I'm sorry, I'm not sure how to parse your prompt. Currently, I want to format the constraints of 
your prompt into a dictionary with the keys: "avoid","goal_lms","pattern","landmark_offset","search", and "pattern_offset". Do you think your prompt constraints can be categorized 
like this or should I edit my constraint dictionary format?"

Prompt: Plant in 1mx1m grid in the bounded area. Avoid driving over wherever youâ€™ve planted or any conmods.


llm_result: {"avoid": "planted areas, conmods", "pattern": "grid", "pattern_offset": 1, "seed": "True"}

results_str:  {"avoid": "planted areas, conmods", "pattern": "grid", "pattern_offset": 1, "seed": "True"}
constraints: {'avoid': 'planted areas, conmods', 'pattern': 'grid', 'pattern_offset': 1, 'seed': True} 

building policy...
feedback is none!
Policy:  1. Validate the initial position of the robot. If the robot is outside the plot bounds, calculate the shortest route to enter the plot and move to that location. 
2. Once inside the bounds, use the RGB cameras to locate any existing "planted areas" or "conmods" to avoid. 
3. Create a dynamic map in the system memory to track these locations and avoid them during the planting process. 
4. Start at one corner of the plot, which will be your initial position, and plan your grid-based route. The grid should have cells of 1m x 1m according to the 'pattern_offset' in the constraints. 
5. Move to the first grid cell location while avoiding any identified obstacles.
6. Upon arrival, plant a seed at the center of the grid cell. 
7. Record the planted location in the system memory. 
8. Proceed to the next grid cell following the planned route. 
9. Repeat steps 5 to 8 for each grid cell within the plot bounds until the entire area is covered. Make sure to avoid all obstacles and previously planted areas as defined in the constraints.
10. Once all the cells within the plot bounds have been planted, confirm completion of the task.
11. Report back to the user the number of seeds planted and their locations. 

Please note that if the robot cannot find a path to a specific grid cell due to obstacles, it will skip that cell and move to the next one. In such a case, the robot will report back to the user about any grid cells that were not planted due to obstructions.
enhanced verification response:  The following paragraph is feedback from the user on a policy. Based on the following response, does the user approve of this policy? Return "True" if so, and "False" otherwise.
If the user suggests any changes, return False. 
That'll do pig that'll do
verifying the policy; this is the llm result: Based on the provided feedback, it is unclear whether the user approves of the policy or not, as their response does not directly express approval, disapproval, or suggestion for changes. Therefore, it is not possible to definitively return "True" or "False". Could you provide more context or clarity?
Found a valid policy approved by the human!
